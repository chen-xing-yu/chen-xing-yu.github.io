---
layout: post
title: Vascular Interventional Surgical Robot
[//]: # (subtitle: There's lots to learn!)
#cover-img: /assets/img/path.png
thumbnail-img: /assets/img/VISR.png
gh-repo: daattali/beautiful-jekyll
tags: [surgical robot]
comments: true
mathjax: true
author: Xing-Yu Chen
---
I have designed an isomorphic master-salve Vascular Interventional Surgical Robot (VISR) for precise force measurement and navigation of endovascular tools viz. catheters and guidewires. The master console aids operators in issuing manipulation commands and logs feedback from the force, rotation, and translation data. The slave manipulator uses the commands received from the master platform for actual tool navigation. Some force sensors are mounted at clamping device of the robot manipulator, so I utilized an Artificial Neural Network (ANN) for guidewire resistance force modulation with 50 mN precision. The developed ANN is a multilayer perceptron with five hidden layers and 77 neurons. The network is used to estimate distal force of guidewire from the force measured from force sensor in robot manipulator. 

<br/><img src='/assets/img/VISR.png'>
<center>Vascular interventional surgical robot designed in SIAT, Chinese Academy of Sciences; (A) Master console; (B) Slave manipulator; (C) Surgeons teleoperate the master console in the room without being exposed to X-rays; (D) Slave manipulator placed next to pig in DSA room.</center>

<br/><img src='/assets/img/control_flow.png'>
<center>Control flow of the VISR. Surgeons teleoperate the doctor’s terminal in the room without X-rays, and the slave manipulator with a robotic arm is placed beside the patient’s bed.</center>


<br/><img src='/assets/img/architecture1.png'>
<center>Layers of the VISR control architecture.</center>

In addition, I utilized fuzzy PID and recurrent neural network (RNN) models such as the Long Short-Term Memory networks (LSTM) and Gated Recurrent Unit (GRU) networks to learn typical motion dynamics when running the master-slave platform. The trained network could estimate the position of the slave robot based on input motion factors. The estimated value and an appropriate compensatory value are then transferred to the slave robotic device in order to map the master platform's movements uniformly.     
The RNN models were implemented in Python and using the Keras library and the TensorFlow framework. The LSTM model contains an input layer (N$\times$3$\times$3), two hidden layer with 32 units each, and a fully connected layer that outputs a predicted value using the rectified linear unit (ReLU) activation function. The LSTM unit may extract essential features from an input sequence and store them in memory. To train the model, experimental data for various step values was stacked together, and feature scaling was applied to the data. 

<br/><img src='/assets/img/position_prediction.png'>
<center>A stacked 2-layer architecture for robot position prediction and compensation using (a) LSTM and (b) GRU model.</center> 


Figure depicts the in-silico evaluations of the GRU and LSTM-based controllers. Although the original error increased to 40\%(2.0mm) of the input command for several phases, the minimum and greatest final errors were 0.001 mm and 0.1mm (2\% of the input command) across the steps. It depicts how the GRU-based controller may estimate the predicted slave robot response ahead of time and then use this to regress the initial position error. To validate the real-time usability of the learning-based models in the VISR, we utilized the Jetson AGX Orin development kit (NVIDIA, CA, USA) for the patient-side robot, and evaluated the model's performance under uniform and varying input commands using the control block diagram. For a typical master's displacement, velocity, and the velocity ratio, the RNN model makes an appropriate prediction and checks for errors.  

<br/><img src='/assets/img/control_block.png'>
<center>Control block with error compensation for the patient-side robot.</center> 
<br/>

### Related Pubulications: 

{: .box-note}
**Paper:** Chen, Xing-Yu, et al. Design and Evaluation of a Learning-based Vascular Interventional Surgery Robot. [Fibers, 10.12 (2022): 106](https://doi.org/10.3390/fib10120106)
[PDF Download](https://chen-xing-yu.github.io/_data/VISR.pdf)
{: .box-note}
**Paper:** Akinyemi, T.O., et al. Adapting Neural-Based Models for Position Error Compensation in Robotic Catheter Systems. [Applied Sciences, 12.21 (2022): 10936](https://doi.org/10.3390/app122110936)

{: .box-note}
**Paper:** Akinyemi, T.O., et al. Interventionalist Hand Motion Recognition with Convolutional Neural Network in Robot-assisted Coronary Interventions. [IEEE Sensors Journal](https://doi.org/10.1109/JSEN.2023.3281009)

{: .box-note}
**Paper:** Duan, Wenke, et al. Technical and Clinical Progress on Robot-Assisted Endovascular Interventions: A Review. [Micromachines. 14.1 (2023): 197](https://doi.org/10.3390/mi14010197)

{: .box-warning}
**CN Patent:** A Tactile-Feedback Device and Method for Surgical Robots. [CN115137483A](https://www.researchgate.net/publication/370801433_CN_Patent_yizhongshoushujiqirendezhuduanliganzhifankuicaozongzhuangzhijifangfa)

 {: .box-warning}
**CN Patent:** A Bidirectional Guidewire Force Measurement Method for Vascular Interventional Surgical Robot. [CN114948258A](https://www.researchgate.net/publication/370801270_CN_Patent_yizhongshuangxiangdianchushijierujiqirencongduandaosilijiancezhuangzhijifangfa)




[//]: # (This is an item in your portfolio. It can be have images or nice text. If you name the file .md, it will be parsed as markdown. If you name the file .html, it will be parsed as HTML. )
